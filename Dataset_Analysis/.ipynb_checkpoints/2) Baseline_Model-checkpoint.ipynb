{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **In this notebook, I will build a baseline model for predicting the aggregated demand from T+1 to T+5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geohash2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/angps/Documents/GrabChallenge/Traffic Management/Data'\n",
    "df = pd.read_csv(os.path.join(data_dir,'cleaned_training.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash6</th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_error</th>\n",
       "      <th>longitude_error</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qp03wc</td>\n",
       "      <td>18</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>-5.353088</td>\n",
       "      <td>90.653687</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qp03pn</td>\n",
       "      <td>10</td>\n",
       "      <td>0.024721</td>\n",
       "      <td>-5.413513</td>\n",
       "      <td>90.664673</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qp09sw</td>\n",
       "      <td>9</td>\n",
       "      <td>0.102821</td>\n",
       "      <td>-5.325623</td>\n",
       "      <td>90.906372</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qp0991</td>\n",
       "      <td>32</td>\n",
       "      <td>0.088755</td>\n",
       "      <td>-5.353088</td>\n",
       "      <td>90.752563</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qp090q</td>\n",
       "      <td>15</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>-5.413513</td>\n",
       "      <td>90.719604</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohash6  day    demand  latitude  longitude  latitude_error  \\\n",
       "0   qp03wc   18  0.020072 -5.353088  90.653687        0.002747   \n",
       "1   qp03pn   10  0.024721 -5.413513  90.664673        0.002747   \n",
       "2   qp09sw    9  0.102821 -5.325623  90.906372        0.002747   \n",
       "3   qp0991   32  0.088755 -5.353088  90.752563        0.002747   \n",
       "4   qp090q   15  0.074468 -5.413513  90.719604        0.002747   \n",
       "\n",
       "   longitude_error  Hour  Minute  Period  \n",
       "0         0.005493    20       0    1712  \n",
       "1         0.005493    14      30     922  \n",
       "2         0.005493     6      15     793  \n",
       "3         0.005493     5       0    2996  \n",
       "4         0.005493     4       0    1360  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Baseline Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will only use data from day 2 onwards so every data point has a previous full day demand data. We would also split the dataset 80-20 for training and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['day'] >= 2]\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=0)\n",
    "train_df = train_df.reset_index(drop=True, inplace=False)\n",
    "val_df = val_df.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3310955, 10), (827739, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the baseline model, we will use the past 96 (day) aggregated demand as the input to a simple LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayhourmin_to_period(day, hour, minute):\n",
    "    return ((day-1) * 24 * 4) + (hour * 4) + minute//15\n",
    "\n",
    "def period_to_dayhourmin(period):\n",
    "    day = period//96 + 1\n",
    "    hour = (period - (day-1) * 96)//4\n",
    "    minute = (period - ((day-1) * 96) - (hour*4)) * 15\n",
    "    return (day, hour, minute)\n",
    "\n",
    "def get_demand_from_period(df, geohash, period):\n",
    "    day, hour, minute = period_to_dayhourmin(period)\n",
    "    demand_queried = df[(df['geohash6'] == geohash) & (df['day'] == day)\n",
    "                & (df['Hour'] == hour) & (df['Minute'] == minute)]['demand'].values\n",
    "    if len(demand_queried) > 0:\n",
    "        return demand_queried[0]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_past_demand(df, geohash, day, hour, minute, num_periods=96):\n",
    "    period = dayhourmin_to_period(day, hour, minute)\n",
    "    return np.array([get_demand_from_period(df, geohash, period - i) for i in range(1, num_periods + 1)])\n",
    "\n",
    "def get_future_demand(df, geohash, day, hour, minute, num_periods=5):\n",
    "    period = dayhourmin_to_period(day, hour, minute)\n",
    "    return np.array([get_demand_from_period(df, geohash, period + i) for i in range(num_periods)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.LSTM object at 0x7f6860366a58>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "WARNING:tensorflow:From /home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "def fc_layer(inputs, output_units, batch_norm=True):\n",
    "    net = tf.keras.layers.Dense(output_units)(inputs)\n",
    "    if batch_norm:\n",
    "        net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.Activation('relu')(net)\n",
    "    return net\n",
    "\n",
    "def baseline_model():\n",
    "    _input = tf.keras.layers.Input(shape=(96,1))\n",
    "    net = tf.keras.layers.LSTM(units=64)(_input)\n",
    "    net = fc_layer(net, 16)\n",
    "    net = tf.keras.layers.Dense(5, kernel_initializer='normal')(net)\n",
    "    model = tf.keras.models.Model(inputs=_input, outputs=net)\n",
    "    return model\n",
    "\n",
    "model = baseline_model()\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error, \n",
    "              metrics =[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                16896     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 18,085\n",
      "Trainable params: 18,053\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(typ, batch_size, past_periods=96):\n",
    "    if typ == 'train':\n",
    "        df = train_df\n",
    "    elif typ == 'val':\n",
    "        df = val_df\n",
    "    max_rows = len(df)\n",
    "    while True:\n",
    "        past_demands = np.zeros((batch_size, past_periods))\n",
    "        future_demands = np.zeros((batch_size, 5))\n",
    "        rows = np.random.choice(a=max_rows, size=batch_size, replace=False)\n",
    "        for i in range(len(rows)):\n",
    "            geohash = df.loc[i, 'geohash6']\n",
    "            day = df.loc[i, 'day']\n",
    "            hour = df.loc[i, 'Hour']\n",
    "            minute = df.loc[i, 'Minute']\n",
    "            past_demands[i] = get_past_demand(df, geohash, day, hour, minute)\n",
    "            future_demands[i] = get_future_demand(df, geohash, day, hour, minute)\n",
    "        yield np.reshape(past_demands, (batch_size, past_periods,1)), future_demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      " 5/20 [======>.......................] - ETA: 9:39 - loss: 0.0482 - mean_squared_error: 0.0023 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-7629b887988d>\", line 9, in <module>\n",
      "    verbose=1)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1426, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 225, in model_iteration\n",
      "    mode='test')\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 177, in model_iteration\n",
      "    batch_data = _get_next_batch(output_generator, mode)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 258, in _get_next_batch\n",
      "    generator_output = next(output_generator)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 743, in get\n",
      "    inputs = self.queue.get(block=True).get()\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/multiprocessing/pool.py\", line 651, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/multiprocessing/pool.py\", line 648, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/angps/anaconda3/envs/deeplearning2/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "train_gen = data_gen('train', batch_size=1)\n",
    "val_gen = data_gen('val', batch_size=1)\n",
    "num_epochs = 10\n",
    "history = model.fit_generator(generator=train_gen,\n",
    "                              validation_data=val_gen,\n",
    "                              steps_per_epoch=20,\n",
    "                              validation_steps=20,\n",
    "                              max_queue_size=20,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
