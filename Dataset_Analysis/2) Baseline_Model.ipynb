{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CHT-m3CjG9ze"
   },
   "source": [
    "# **In this notebook, I will build a baseline model for predicting the aggregated demand from T+1 to T+5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5158,
     "status": "ok",
     "timestamp": 1560063703276,
     "user": {
      "displayName": "Peng Seng (BfE Data Analytics Director)",
      "photoUrl": "",
      "userId": "03000862672762938356"
     },
     "user_tz": -480
    },
    "id": "GTVYjLRSG9zg",
    "outputId": "dbdad158-57ed-4a22-cf9a-2d9209d4da8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geohash2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NpivAESAHVsv"
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/angps/Documents/GrabChallenge/Traffic Management/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3SzdAAF-G9zr"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir,'cleaned_training.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9972,
     "status": "ok",
     "timestamp": 1560063709751,
     "user": {
      "displayName": "Peng Seng (BfE Data Analytics Director)",
      "photoUrl": "",
      "userId": "03000862672762938356"
     },
     "user_tz": -480
    },
    "id": "fVuAfIYSG9zw",
    "outputId": "a26aaca7-0d3d-441c-e22b-c3e5bab5e808"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash6</th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_error</th>\n",
       "      <th>longitude_error</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qp03wc</td>\n",
       "      <td>18</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>-5.353088</td>\n",
       "      <td>90.653687</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qp03pn</td>\n",
       "      <td>10</td>\n",
       "      <td>0.024721</td>\n",
       "      <td>-5.413513</td>\n",
       "      <td>90.664673</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qp09sw</td>\n",
       "      <td>9</td>\n",
       "      <td>0.102821</td>\n",
       "      <td>-5.325623</td>\n",
       "      <td>90.906372</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qp0991</td>\n",
       "      <td>32</td>\n",
       "      <td>0.088755</td>\n",
       "      <td>-5.353088</td>\n",
       "      <td>90.752563</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qp090q</td>\n",
       "      <td>15</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>-5.413513</td>\n",
       "      <td>90.719604</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohash6  day    demand  latitude  longitude  latitude_error  \\\n",
       "0   qp03wc   18  0.020072 -5.353088  90.653687        0.002747   \n",
       "1   qp03pn   10  0.024721 -5.413513  90.664673        0.002747   \n",
       "2   qp09sw    9  0.102821 -5.325623  90.906372        0.002747   \n",
       "3   qp0991   32  0.088755 -5.353088  90.752563        0.002747   \n",
       "4   qp090q   15  0.074468 -5.413513  90.719604        0.002747   \n",
       "\n",
       "   longitude_error  Hour  Minute  Period  \n",
       "0         0.005493    20       0    1712  \n",
       "1         0.005493    14      30     922  \n",
       "2         0.005493     6      15     793  \n",
       "3         0.005493     5       0    2996  \n",
       "4         0.005493     4       0    1360  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Naive Forecast**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the baseline T+1 forecast RMSE if we use naive forecast (where T+1 is predicted to be the same as T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash6</th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_error</th>\n",
       "      <th>longitude_error</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2873712</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>-5.484924</td>\n",
       "      <td>90.653687</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643238</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010292</td>\n",
       "      <td>-5.484924</td>\n",
       "      <td>90.653687</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791986</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006676</td>\n",
       "      <td>-5.484924</td>\n",
       "      <td>90.653687</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022333</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>-5.484924</td>\n",
       "      <td>90.653687</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848343</th>\n",
       "      <td>qp02yc</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>-5.484924</td>\n",
       "      <td>90.653687</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geohash6  day    demand  latitude  longitude  latitude_error  \\\n",
       "2873712   qp02yc    1  0.020592 -5.484924  90.653687        0.002747   \n",
       "2643238   qp02yc    1  0.010292 -5.484924  90.653687        0.002747   \n",
       "1791986   qp02yc    1  0.006676 -5.484924  90.653687        0.002747   \n",
       "4022333   qp02yc    1  0.003822 -5.484924  90.653687        0.002747   \n",
       "3848343   qp02yc    1  0.011131 -5.484924  90.653687        0.002747   \n",
       "\n",
       "         longitude_error  Hour  Minute  Period  \n",
       "2873712         0.005493     2      45      11  \n",
       "2643238         0.005493     3       0      12  \n",
       "1791986         0.005493     4       0      16  \n",
       "4022333         0.005493     4      30      18  \n",
       "3848343         0.005493     6      45      27  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(['geohash6','Period'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = df['demand'].values\n",
    "pred = demand[:-1]\n",
    "actual = demand[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for naive forecast for T+1: \n",
      "tf.Tensor(0.03464925396052445, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "x = rmse(actual, pred)\n",
    "print('RMSE for naive forecast for T+1: ') \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The RMSE for T+1 using naive forecast is about 3.5%, which is pretty good.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxHb4GUwG9z3"
   },
   "source": [
    "## **Baseline Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8C1yM6kyG9z4"
   },
   "source": [
    "**We will only use data from day 15 onwards so every data point has a previous full 14 day demand data. We would also split the dataset 80-20 for training and test set. A simple LSTM will be used.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayhourmin_to_period(day, hour, minute):\n",
    "    return ((day-1) * 24 * 4) + (hour * 4) + minute//15\n",
    "\n",
    "def period_to_dayhourmin(period):\n",
    "    day = period//96 + 1\n",
    "    hour = (period - (day-1) * 96)//4\n",
    "    minute = (period - ((day-1) * 96) - (hour*4)) * 15\n",
    "    return (day, hour, minute)\n",
    "\n",
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data\n",
    "\n",
    "def onehot(day):\n",
    "    day = (day-1) % 7\n",
    "    ls = [0] * 7\n",
    "    ls[day] = 1\n",
    "    return np.array(ls) \n",
    "\n",
    "df = encode(df, 'Hour', 23)\n",
    "df = encode(df, 'Minute', 45)\n",
    "\n",
    "\n",
    "def get_feats(df, geohash, period, num_past_per):\n",
    "    temp_df = df[(df['geohash6']==geohash) & (df['Period']<=period)].sort_values('Period', ascending=False).reset_index(drop=True, inplace=False)\n",
    "    past_demands = temp_df.demand.values[1:num_past_per+1].astype(float)\n",
    "    past_periods = temp_df.Period.values[1:num_past_per+1].astype(int)\n",
    "    feats = np.array([])\n",
    "    for i in range(num_past_per):\n",
    "        day,hour,minute = period_to_dayhourmin(past_periods[i])\n",
    "        days_feat = onehot(day)\n",
    "        time_feat = temp_df.loc[i,['Hour_sin', 'Hour_cos', 'Minute_sin', 'Minute_cos']].values.astype(float)\n",
    "        feat = np.concatenate((np.array([past_demands[i]]), days_feat, time_feat),axis=None)\n",
    "        feats = np.vstack((feats,feat)) if feats.size else feat\n",
    "    return feats\n",
    "\n",
    "def get_demand_from_period(df, geohash, period):\n",
    "    demand_queried = df[(df['geohash6'] == geohash) & (df['Period']==period)]['demand'].values\n",
    "    if len(demand_queried) > 0:\n",
    "        return demand_queried[0]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utwryLm0G90Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_gen(typ, batch_size, num_past_per=24):\n",
    "    import time\n",
    "    if typ == 'train':\n",
    "        df = train_df\n",
    "    elif typ == 'val':\n",
    "        df = val_df\n",
    "    df_1 = df[(df['day'] > 14) & (df['day'] < 60)].reset_index(drop=True, inplace=False)\n",
    "    max_rows = len(df_1)\n",
    "    while True:\n",
    "        feats = np.zeros((batch_size, num_past_per, 12))\n",
    "        future_demands = np.zeros((batch_size, 1))\n",
    "        rows = np.random.choice(a=max_rows, size=batch_size, replace=False)\n",
    "        for i in range(len(rows)):\n",
    "            row = rows[i]\n",
    "            geohash = df_1.loc[row, 'geohash6']\n",
    "            period = df_1.loc[row, 'Period']\n",
    "            feats[i] = get_feats(df, geohash, period, num_past_per)\n",
    "            future_demands[i] = get_demand_from_period(df, geohash, period)\n",
    "        yield feats, future_demands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7637,
     "status": "ok",
     "timestamp": 1560063711807,
     "user": {
      "displayName": "Peng Seng (BfE Data Analytics Director)",
      "photoUrl": "",
      "userId": "03000862672762938356"
     },
     "user_tz": -480
    },
    "id": "vb8bHsMHG90J",
    "outputId": "c92f4ae1-6bef-440e-f7b6-f6b6a69c0cb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "def fc_layer(inputs, output_units, batch_norm=True):\n",
    "    net = tf.keras.layers.Dense(output_units)(inputs)\n",
    "    if batch_norm:\n",
    "        net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.Activation('relu')(net)\n",
    "    return net\n",
    "\n",
    "def baseline_model():\n",
    "    _input = tf.keras.layers.Input(shape=(24,12))\n",
    "    net = tf.keras.layers.CuDNNLSTM(units=32)(_input)\n",
    "    #net = fc_layer(net, 16)\n",
    "    net = tf.keras.layers.BatchNormalization()(net)\n",
    "    net = tf.keras.layers.Activation('relu')(net)\n",
    "    net = tf.keras.layers.Dense(1, kernel_initializer='normal', activation='relu')(net)\n",
    "    model = tf.keras.models.Model(inputs=_input, outputs=net)\n",
    "    return model\n",
    "\n",
    "model = baseline_model()\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error, \n",
    "              metrics =[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6017,
     "status": "ok",
     "timestamp": 1560063711812,
     "user": {
      "displayName": "Peng Seng (BfE Data Analytics Director)",
      "photoUrl": "",
      "userId": "03000862672762938356"
     },
     "user_tz": -480
    },
    "id": "axHPx8yWG90Q",
    "outputId": "53c567d0-e08d-48bf-d304-0be1ffeaa1aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 24, 12)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 32)                5888      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,049\n",
      "Trainable params: 5,985\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[(df['day'] > 20) & (df['day'] < 60)]\n",
    "df = df.groupby('geohash6').filter(lambda x: len(x)>600)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=0, stratify=df[['geohash6']])\n",
    "train_df = train_df.reset_index(drop=True, inplace=False)\n",
    "val_df = val_df.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3327996, 14), (832000, 14))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1324721,
     "status": "ok",
     "timestamp": 1560065039726,
     "user": {
      "displayName": "Peng Seng (BfE Data Analytics Director)",
      "photoUrl": "",
      "userId": "03000862672762938356"
     },
     "user_tz": -480
    },
    "id": "QGvRJdQlG90f",
    "outputId": "07218040-d63e-4237-bf64-61b4c0c475d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /home/angps/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "20/20 [==============================] - 337s 17s/step - loss: 0.0946 - mean_squared_error: 0.0315\n",
      "20/20 [==============================] - 740s 37s/step - loss: 0.1025 - mean_squared_error: 0.0363 - val_loss: 0.0946 - val_mean_squared_error: 0.0315\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 330s 16s/step - loss: 0.0973 - mean_squared_error: 0.0346\n",
      "20/20 [==============================] - 519s 26s/step - loss: 0.0840 - mean_squared_error: 0.0259 - val_loss: 0.0973 - val_mean_squared_error: 0.0346\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 332s 17s/step - loss: 0.1029 - mean_squared_error: 0.0372\n",
      "20/20 [==============================] - 517s 26s/step - loss: 0.0754 - mean_squared_error: 0.0181 - val_loss: 0.1029 - val_mean_squared_error: 0.0372\n",
      "Epoch 4/5\n",
      " 8/20 [===========>..................] - ETA: 3:48 - loss: 0.0798 - mean_squared_error: 0.0237"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-06f767ea433b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                               \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                               verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m           mode='test')\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(output_generator, mode)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# Returning `None` will trigger looping to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning2/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning2/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning2/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning2/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning2/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_gen = data_gen('train', batch_size=32)\n",
    "val_gen = data_gen('val', batch_size=32)\n",
    "num_epochs = 5\n",
    "base_lr = 0.001\n",
    "\n",
    "\n",
    "def lr_linear_decay(epoch):\n",
    "    return (base_lr * (1 - (epoch/num_epochs)))\n",
    "\n",
    "history = model.fit_generator(generator=train_gen,\n",
    "                              validation_data=val_gen,\n",
    "                              steps_per_epoch=20,\n",
    "                              validation_steps=20,\n",
    "                              max_queue_size=10,\n",
    "                              epochs=num_epochs,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the simple LSTM model doesn't work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hDIJ2pLG90x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2) Baseline_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
